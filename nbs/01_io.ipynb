{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Video\n",
    "> Cinelytics uses OpenCV to read video. The main function is `read_video`, where you can flexibly grab either all or different sequences of the frames of any given video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from videoutils.utils import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['read_video', 'read_all_frames', 'read_specific_frames',\n",
    "           'capture', 'as_tensor', 'as_normalised_tensor', 'lapply']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_video(fname: Union[str, cv2.VideoCapture],\n",
    "               target_frames: Union[tuple, list, int, np.array, None]=None,\n",
    "               apply: Callable=None) -> Union[torch.Tensor, list]:\n",
    "    \"\"\"Flexible video reader where you can grab frames in different ways\n",
    "    and return as different dtypes.\n",
    "    \"\"\"\n",
    "    cap    = capture(fname)\n",
    "    frames = read_all_frames(cap) if target_frames is None else read_specific_frames(cap, target_frames)\n",
    "    cap.release()\n",
    "\n",
    "    if apply is not None:\n",
    "        if apply == as_tensor: frames = torch.stack(lapply(frames, apply))\n",
    "        else: frames = lapply(frames, apply)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Args**:\n",
    "* `fname`: path to the video file, or a `cv2.VideoCapture` object\n",
    "* `target_frames`: if `None`, all the frames of `fname` are read. Else, if it is a\n",
    "    - `int`: returns frame at this index\n",
    "    - `list`/`np.array`: returns frame at the indices of each element\n",
    "    - `tuple`: <br>a tuple like `(start_idx, end_idx, stride)` where `stride` is optional and if `stride=2`, after reading the first frame, every _2nd/(stride)th_ frame is read\n",
    "* `apply`: a function that transforms a `np.array` of shape `(height, width, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_all_frames(cap: cv2.VideoCapture) -> list:\n",
    "    \"Read all frames from a `cv2.VideoCapture` object\"\n",
    "    frames=[]\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret is True: frames.append(bgr2rgb(frame))\n",
    "        else: break\n",
    "\n",
    "    num_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if not len(frames) == num_frames: print(f'Only read in {num_frames} / {len(frames)}')\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_specific_frames(cap: cv2.VideoCapture, \n",
    "                         target_frames: Union[tuple, list, int, np.array]) -> list:\n",
    "    \"Read specific frames from a `cv2.VideoCapture` object\"\n",
    "    if   isinstance(target_frames, tuple) : frame_idxs = np.arange(*target_frames)\n",
    "    elif isinstance(target_frames, list)  : frame_idxs = target_frames\n",
    "    elif isinstance(target_frames, int)   : frame_idxs = [target_frames]\n",
    "    elif isinstance(target_frames, np.ndarray)   : frame_idxs = target_frames \n",
    "\n",
    "    frames=[]\n",
    "    for i in frame_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True: frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # return np.array\n",
    "        else: break\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def capture(x: Union[str, cv2.VideoCapture]) -> cv2.VideoCapture:\n",
    "    \"Ensure `cv2.VideoCapture` works properly\"\n",
    "    assert isinstance(x, (str, cv2.VideoCapture)), \\\n",
    "    f\"Expected `str` or `cv2.VideoCapture` but received {type(x)} \"\n",
    "    cap = cv2.VideoCapture(x) if isinstance(x, str) else x\n",
    "    assert(cap.isOpened()), f'Failed to open video \"{x}\"'\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid); vid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=np.arange(100),\n",
    "                 apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 480, 720])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=(0, 50, 2),\n",
    "                 apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 480, 720])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid); vid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_io.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
