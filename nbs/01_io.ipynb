{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Video\n",
    "> Cinelytics uses OpenCV to read video. The main function is `read_video`, where you can flexibly grab either all or different sequences of the frames of any given video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:21.480765Z",
     "start_time": "2019-12-21T04:25:21.477575Z"
    }
   },
   "outputs": [],
   "source": [
    "#default_exp io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:22.085303Z",
     "start_time": "2019-12-21T04:25:21.728381Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:23.229833Z",
     "start_time": "2019-12-21T04:25:22.089069Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from cinelytics.imports import *\n",
    "from cinelytics.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:23.250671Z",
     "start_time": "2019-12-21T04:25:23.231667Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "fname = 'files/tsn-#5.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:24.410781Z",
     "start_time": "2019-12-21T04:25:24.388479Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_video(fname: Union[str, cv2.VideoCapture],\n",
    "               target_frames: Union[tuple, list, int, np.array, None]=None,\n",
    "               apply: Callable=None) -> Union[torch.Tensor, list]:\n",
    "    \"\"\"Flexible video reader where you can grab frames in different ways\n",
    "    and return as different dtypes.\n",
    "    \"\"\"\n",
    "    cap    = capture(fname)\n",
    "    frames = read_all_frames(cap) if target_frames is None else read_specific_frames(cap, target_frames)\n",
    "    cap.release()\n",
    "\n",
    "    if apply is not None:\n",
    "        if apply == as_tensor: frames = torch.stack(lapply(frames, apply))\n",
    "        else: frames = lapply(frames, apply)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Args**:\n",
    "* `fname`: path to the video file, or a `cv2.VideoCapture` object\n",
    "* `target_frames`: if `None`, all the frames of `fname` are read. Else, if it is a\n",
    "    - `int`: returns frame at this index\n",
    "    - `list`/`np.array`: returns frame at the indices of each element\n",
    "    - `tuple`: <br>a tuple like `(start_idx, end_idx, stride)` where `stride` is optional and if `stride=2`, after reading the first frame, every _2nd/(stride)th_ frame is read\n",
    "* `apply`: a function that transforms a `np.array` of shape `(height, width, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:26.656622Z",
     "start_time": "2019-12-21T04:25:26.629055Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_all_frames(cap: cv2.VideoCapture) -> list:\n",
    "    \"Read all frames from a `cv2.VideoCapture` object\"\n",
    "    frames=[]\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret is True: frames.append(bgr2rgb(frame))\n",
    "        else: break\n",
    "\n",
    "    num_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if not len(frames) == num_frames: print(f'Only read in {num_frames} / {len(frames)}')\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:27.780477Z",
     "start_time": "2019-12-21T04:25:27.755793Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_specific_frames(cap: cv2.VideoCapture, \n",
    "                         target_frames: Union[tuple, list, int, np.array]) -> list:\n",
    "    \"Read specific frames from a `cv2.VideoCapture` object\"\n",
    "    if   isinstance(target_frames, tuple) : frame_idxs = np.arange(*target_frames)\n",
    "    elif isinstance(target_frames, list)  : frame_idxs = target_frames\n",
    "    elif isinstance(target_frames, int)   : frame_idxs = [target_frames]\n",
    "    elif isinstance(target_frames, np.ndarray)   : frame_idxs = target_frames \n",
    "\n",
    "    frames=[]\n",
    "    for i in frame_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True: frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # return np.array\n",
    "        else: break\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:29.433195Z",
     "start_time": "2019-12-21T04:25:29.394270Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def capture(x: Union[str, cv2.VideoCapture]) -> cv2.VideoCapture:\n",
    "    \"Ensure `cv2.VideoCapture` works properly\"\n",
    "    assert isinstance(x, (str, cv2.VideoCapture)), \\\n",
    "    f\"Expected `str` or `cv2.VideoCapture` but received {type(x)} \"\n",
    "    cap = cv2.VideoCapture(x) if isinstance(x, str) else x\n",
    "    assert(cap.isOpened()), f'Failed to open video \"{x}\"'\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:30.926724Z",
     "start_time": "2019-12-21T04:25:30.778793Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=[0,1,2,3,4,5],\n",
    "                 apply=as_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:31.552100Z",
     "start_time": "2019-12-21T04:25:31.533048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Image (3, 480, 720),\n",
       " Image (3, 480, 720),\n",
       " Image (3, 480, 720),\n",
       " Image (3, 480, 720),\n",
       " Image (3, 480, 720),\n",
       " Image (3, 480, 720)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:38.449586Z",
     "start_time": "2019-12-21T04:25:34.967508Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=np.arange(100),\n",
    "                 apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:38.489587Z",
     "start_time": "2019-12-21T04:25:38.453096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 480, 720])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:39.485061Z",
     "start_time": "2019-12-21T04:25:38.493171Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=(0, 50, 2),\n",
    "                 apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:25:39.519959Z",
     "start_time": "2019-12-21T04:25:39.489818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 480, 720])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:26:27.018300Z",
     "start_time": "2019-12-21T04:26:26.957885Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T04:29:57.475468Z",
     "start_time": "2019-12-21T04:29:57.453051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid); vid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informal Tests -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "x = read_video(fname, (0, 10, 2))\n",
    "assert len(x) == 5\n",
    "assert type(x[0]) == np.ndarray\n",
    "\n",
    "x = read_video(fname)\n",
    "assert len(x) == 53\n",
    "assert type(x[0]) == np.ndarray\n",
    "\n",
    "x = read_video(fname, 2)\n",
    "assert len(x) == 1\n",
    "assert type(x[0]) == np.ndarray\n",
    "\n",
    "x = read_video(fname, [0, 2, 3])\n",
    "assert len(x) == 3\n",
    "assert type(x[0]) == np.ndarray\n",
    "\n",
    "x = read_video(fname, [0, 2, 3], as_img)\n",
    "assert len(x) == 3\n",
    "assert type(x[0]) == Image\n",
    "\n",
    "x = read_video(fname, [0, 2, 3], as_tensor)\n",
    "assert len(x) == 3\n",
    "assert type(x[0]) == torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_io.ipynb.\n",
      "Converted 02a_cut_detection.detect_peaks.ipynb.\n",
      "Converted 02b_cut_detection.split_shots.ipynb.\n",
      "Converted 03_detect_scale.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted modules.clip.ipynb.\n",
      "Converted modules.scene.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
