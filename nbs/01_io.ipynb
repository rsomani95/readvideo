{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Video\n",
    "> Cinelytics uses OpenCV to read video. The main function is `read_video`, where you can flexibly grab either all or different sequences of the frames of any given video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from videoutils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "__all__ = ['read_video', 'read_frames', 'get_target_frames', 'capture', 'as_tensor', 'as_normalised_tensor', 'lapply']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_video(fname         : Union[str, cv2.VideoCapture],\n",
    "               start_idx     : Optional[int]=None,\n",
    "               end_idx       : Optional[int]=None,\n",
    "               frame_stride  : Optional[int]=None,\n",
    "               target_frames : Union[tuple, list, int, np.array]=None,\n",
    "               apply         : Optional[Callable]=None) -> Union[torch.Tensor, list]:\n",
    "    \"\"\"\n",
    "    Flexible video reader where you can grab frames in different ways\n",
    "    and return as different dtypes.\n",
    "    \n",
    "    **Args**\n",
    "    \n",
    "    * `fname`        : a `cv2.VideoCapture` object, or path to the video file\n",
    "    * `start_idx`    : index of the frame where you'd like to start reading the file\n",
    "    * `end_idx`      : index of the frame where you'd like to end reading the file\n",
    "    * `frame_stride` : after reading the frame, every `frame_stride`th index will be read\n",
    "    * `target_frames`: if this arg is used, `start_idx`, `end_idx`, and `frame_stride` are ignored. Can be an \n",
    " \n",
    "            - `int`            : returns frame at this index\n",
    "            - `list`/`np.array`: returns frame at index of each element\n",
    "            - `tuple`          : a tuple like `(start_idx, end_idx, frame_stride)` where \n",
    "                                 `frame_stride`is optional. If this is what you want, using the \n",
    "                                 other args instead of `target_frames` is more flexible.\n",
    "    * `apply`         : a function that transforms a single `np.array` of shape `(height, width, channels)`\n",
    "    \"\"\"\n",
    "    cap    = capture(fname)\n",
    "    if target_frames is None: target_frames = get_target_frames(fname, start_idx, end_idx, frame_stride)\n",
    "    frames = read_frames(cap, target_frames)\n",
    "    cap.release()\n",
    "\n",
    "    if apply is not None:\n",
    "        if apply == as_tensor or as_normalised_tensor: frames = torch.stack(lapply(frames, apply))\n",
    "        else: frames = lapply(frames, apply)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_frames(cap: cv2.VideoCapture, \n",
    "                target_frames: Union[tuple, list, int, np.array]) -> list:\n",
    "    \"Read specific frames from a `cv2.VideoCapture` object\"\n",
    "    if   isinstance(target_frames, tuple) : frame_idxs = np.arange(*target_frames)\n",
    "    elif isinstance(target_frames, list)  : frame_idxs = target_frames\n",
    "    elif isinstance(target_frames, int)   : frame_idxs = [target_frames]\n",
    "    elif isinstance(target_frames, np.ndarray)   : frame_idxs = target_frames \n",
    "\n",
    "    frames=[]\n",
    "    for i in frame_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True: frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # return np.array\n",
    "        else: break\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def capture(x: Union[str, cv2.VideoCapture]) -> cv2.VideoCapture:\n",
    "    \"Ensure `cv2.VideoCapture` works properly\"\n",
    "    assert isinstance(x, (str, cv2.VideoCapture)), \\\n",
    "    f\"Expected `str` or `cv2.VideoCapture` but received {type(x)} \"\n",
    "    cap = cv2.VideoCapture(x) if isinstance(x, str) else x\n",
    "    assert(cap.isOpened()), f'Failed to open video \"{x}\"'\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_target_frames(file, start, end, stride):\n",
    "    \"flexibly get the indixes of the frames you want to grab\"\n",
    "    num_frames = capture(file).get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if start is not None:\n",
    "        if end is None: return np.arange(0, num_frames, stride)\n",
    "        else:           return np.arange(start, end, stride)\n",
    "    if start is None:\n",
    "        if end is None: return np.arange(0, num_frames, stride)\n",
    "        else:           return np.arange(0, end, stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4', target_frames=[0,1,2,3,4,5])\n",
    "\n",
    "len(vid); vid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid  = read_video('files/interstellar-waves-edit.mp4', target_frames=np.arange(100))\n",
    "vid2 = read_video('files/interstellar-waves-edit.mp4', start_idx=0, end_idx=100, frame_stride=1)\n",
    "vid3 = read_video('files/interstellar-waves-edit.mp4', target_frames=(0, 100, 1))\n",
    "vid4 = read_video('files/interstellar-waves-edit.mp4', end_idx=100)\n",
    "\n",
    "len(vid)\n",
    "len(vid) == len(vid2) == len(vid3) == len(vid4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4', target_frames=5, apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 480, 720])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_io.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
