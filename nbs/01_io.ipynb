{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Video\n",
    "> Cinelytics uses OpenCV to read video. The main function is `read_video`, where you can flexibly grab either all or different sequences of the frames of any given video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:09.459279Z",
     "start_time": "2019-12-21T05:32:09.456943Z"
    }
   },
   "outputs": [],
   "source": [
    "#default_exp io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:09.773849Z",
     "start_time": "2019-12-21T05:32:09.460670Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.025903Z",
     "start_time": "2019-12-21T05:32:09.775110Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from videoutils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.040536Z",
     "start_time": "2019-12-21T05:32:10.027597Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_video(fname: Union[str, cv2.VideoCapture],\n",
    "               target_frames: Union[tuple, list, int, np.array, None]=None,\n",
    "               apply: Callable=None) -> Union[torch.Tensor, list]:\n",
    "    \"\"\"Flexible video reader where you can grab frames in different ways\n",
    "    and return as different dtypes.\n",
    "    \"\"\"\n",
    "    cap    = capture(fname)\n",
    "    frames = read_all_frames(cap) if target_frames is None else read_specific_frames(cap, target_frames)\n",
    "    cap.release()\n",
    "\n",
    "    if apply is not None:\n",
    "        if apply == as_tensor: frames = torch.stack(lapply(frames, apply))\n",
    "        else: frames = lapply(frames, apply)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Args**:\n",
    "* `fname`: path to the video file, or a `cv2.VideoCapture` object\n",
    "* `target_frames`: if `None`, all the frames of `fname` are read. Else, if it is a\n",
    "    - `int`: returns frame at this index\n",
    "    - `list`/`np.array`: returns frame at the indices of each element\n",
    "    - `tuple`: <br>a tuple like `(start_idx, end_idx, stride)` where `stride` is optional and if `stride=2`, after reading the first frame, every _2nd/(stride)th_ frame is read\n",
    "* `apply`: a function that transforms a `np.array` of shape `(height, width, channels)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.059537Z",
     "start_time": "2019-12-21T05:32:10.041974Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_all_frames(cap: cv2.VideoCapture) -> list:\n",
    "    \"Read all frames from a `cv2.VideoCapture` object\"\n",
    "    frames=[]\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret is True: frames.append(bgr2rgb(frame))\n",
    "        else: break\n",
    "\n",
    "    num_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    if not len(frames) == num_frames: print(f'Only read in {num_frames} / {len(frames)}')\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.073520Z",
     "start_time": "2019-12-21T05:32:10.060994Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def read_specific_frames(cap: cv2.VideoCapture, \n",
    "                         target_frames: Union[tuple, list, int, np.array]) -> list:\n",
    "    \"Read specific frames from a `cv2.VideoCapture` object\"\n",
    "    if   isinstance(target_frames, tuple) : frame_idxs = np.arange(*target_frames)\n",
    "    elif isinstance(target_frames, list)  : frame_idxs = target_frames\n",
    "    elif isinstance(target_frames, int)   : frame_idxs = [target_frames]\n",
    "    elif isinstance(target_frames, np.ndarray)   : frame_idxs = target_frames \n",
    "\n",
    "    frames=[]\n",
    "    for i in frame_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True: frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) # return np.array\n",
    "        else: break\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.086428Z",
     "start_time": "2019-12-21T05:32:10.075425Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def capture(x: Union[str, cv2.VideoCapture]) -> cv2.VideoCapture:\n",
    "    \"Ensure `cv2.VideoCapture` works properly\"\n",
    "    assert isinstance(x, (str, cv2.VideoCapture)), \\\n",
    "    f\"Expected `str` or `cv2.VideoCapture` but received {type(x)} \"\n",
    "    cap = cv2.VideoCapture(x) if isinstance(x, str) else x\n",
    "    assert(cap.isOpened()), f'Failed to open video \"{x}\"'\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for `read_video`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.188319Z",
     "start_time": "2019-12-21T05:32:10.088000Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:10.204299Z",
     "start_time": "2019-12-21T05:32:10.189910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid); vid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.037348Z",
     "start_time": "2019-12-21T05:32:10.205701Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=np.arange(100),\n",
    "                 apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.051534Z",
     "start_time": "2019-12-21T05:32:12.039042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 480, 720])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.530547Z",
     "start_time": "2019-12-21T05:32:12.053099Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=(0, 50, 2),\n",
    "                 apply=as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.543886Z",
     "start_time": "2019-12-21T05:32:12.532054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 480, 720])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.594058Z",
     "start_time": "2019-12-21T05:32:12.545231Z"
    }
   },
   "outputs": [],
   "source": [
    "vid = read_video('files/interstellar-waves-edit.mp4',\n",
    "                 target_frames=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.610716Z",
     "start_time": "2019-12-21T05:32:12.595725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(480, 720, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vid); vid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T05:32:12.868656Z",
     "start_time": "2019-12-21T05:32:12.612116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_io.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
